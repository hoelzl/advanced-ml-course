{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wolfgang Rosenstiel Forum für KI\n",
    "\n",
    "## Was ist Maschinelles Lernen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Eine Antwort (Arthur Samuel)\n",
    "\n",
    "Maschinelles Lernen ist ein Feld der Künstlichen Intelligenz. Es wendet statistische Techniken an, um Computern die Fähigkeit zu verleihen, aus Daten zu lernen, ohne explizit programmiert zu sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Andere Antwort (nach Andrew Glassner)\n",
    "\n",
    "- Techniken, die Information aus Daten extrahieren\n",
    "- *Daten:* alles was man messen und aufzeichnen kann\n",
    "- *Information:* was wir interessant finden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/ag/Figure-01-001.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/ag/Figure-01-002.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Andere Antwort (frei nach François Chollet)\n",
    "\n",
    "- Ein Teilgebiet der künstlichen Intelligenz\n",
    "- KI: Automatisierung von Aufgaben, die bisher nur Menschen erledigen konnten\n",
    "  - Das geht auch mit regelbasierten Systemen\n",
    "  - Beispiel: Schach, Expertensystem\n",
    "- ML: Der Teil der KI, der versucht Verhalten zu verbessern, wenn mehr Daten zur Verfügung stehen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Regelbasierte Systeme: Feature Engineering\n",
    "\n",
    "Extraktion von relevanten Features aus Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/ag/Figure-01-003.png\" style=\"width: 40%; margin-left: auto; margin-right: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/ag/Figure-01-004.png\" style=\"width: 20%; margin-left: auto; margin-right: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Nochmal François Chollet\n",
    "\n",
    "- Traditionelles Programmieren:\n",
    "    - Wir programmieren eine Lösung für ein Problem:\n",
    "    - Regeln + Daten $\\Rightarrow$ Antworten\n",
    "- ML:\n",
    "    - Wir extrahieren Regeln aus (gelabelten) Daten\n",
    "    - Daten + Antworten $\\Rightarrow$ Regeln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Was ist Deep Learning\n",
    "\n",
    "- Eine Form von ML, die auf künstlichen neuronalen Netzen basiert\n",
    "- Im Deep Learning erfolgt die Berechnung in \"Schichten\", die immer algemeinere Features extrahieren\n",
    "- Deep Learning benötigt weniger Feature Engineering als andere Ansätze\n",
    "- Braucht aber (meistens) mehr Daten!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Klassifizierung\n",
    "\n",
    "<img src=\"img/ag/Figure-01-022.png\" style=\"float: right;width: 40%;\"/>\n",
    "\n",
    "\n",
    "- Viele Daten, vorgegebene Menge an möglichen Werten\n",
    "- Weise jedem Datensatz einen oder mehrere Labels zu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "def is_cat(x): return x[0].isupper()\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Clustering\n",
    "\n",
    "<img src=\"img/ag/Figure-01-013.jpg\" style=\"float: right;width: 40%;\"/>\n",
    "\n",
    "- Viele Datenpunkte\n",
    "- Finde heraus, welche \"ähnlich\" sind\n",
    "\n",
    "Often mit \"unsupervised\" Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Regression\n",
    "\n",
    "<img src=\"img/ag/Figure-01-011.png\" style=\"float: right;width: 40%;\"/>\n",
    "\n",
    "- Lerne numerische Beziehungen\n",
    "- Wie hängt das Gehalt von Jahren Berufserfahrung ab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Geocoding / Toponym-Auflösung\n",
    "\n",
    "<img src=\"img/france.jpg\" style=\"float: right;width: 40%;\"/>\n",
    "\n",
    "<div style=\"float: left; width: 60%;\">\n",
    "\n",
    "<br/>\n",
    "\n",
    "- Finde Koordinaten, die zum Vorkommen von Namen in Text gehören\n",
    "- Inverses Geocoding: Welcher Ortsname gehört zu Koordinaten\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## (Extractive) Question Answering\n",
    "\n",
    "<img src=\"img/question-mark.jpg\" style=\"float: right;width: 30%;\"/>\n",
    "\n",
    "\n",
    "- Textdokument, Frage basierend auf dem Dokument\n",
    "- Extrahiere die Antwort aus dem Dokument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vorgehensweise beim Supervised Learning\n",
    "\n",
    "<img src=\"img/ag/Figure-01-007.png\" style=\"float: right;width: 40%; padding: 20pt;\"/>\n",
    "\n",
    "- Modell: Algorithmus mitveränderbaren<br/>\n",
    "  Parametern\n",
    "- Datenpunkte mit Labels\n",
    "- Generalisiere die Information<br/>\n",
    "  in den gelabelten Daten\n",
    "- Verbessere die Performance des<br/>\n",
    "  Systems durch \"Tunen\" der Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Einfaches Beispiel: Lineare Regression\n",
    "\n",
    "- Ein einziges numerisches Feature\n",
    "- Ein numerisches Label\n",
    "- Wir versuchen eine lineare Funktion der Form $y = w x + b$ zu finden, die \"möglichst gut passt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Daten\n",
    "\n",
    "- Wir erzeugen uns für dieses Beispiel synthetische Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "num_samples = 80\n",
    "\n",
    "plt.scatter(range(num_samples), torch.rand(num_samples), color='orange')\n",
    "plt.scatter(range(num_samples), torch.randn(num_samples), color='blue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(torch.rand(100 * num_samples).numpy(), bins=num_samples, color='orange')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(torch.randn(100 * num_samples).numpy(), bins=num_samples, color='blue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "x = torch.rand(num_samples) * 10\n",
    "y = 5 * x - 10 + 5 * torch.randn(num_samples)\n",
    "x[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Realistischer\n",
    "\n",
    "<img src=\"img/ag/Figure-01-007.png\" style=\"width: 70%; margin-left: auto; margin-right: auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Anpassen eines Linearen Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, w, b):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bestimmen der Qualität: Loss\n",
    "\n",
    "- Verschiedene Varianten: \n",
    "- RMSE\n",
    "- MSE \n",
    "- MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_pred, y_true):\n",
    "    squared_diffs = (y_pred - y_true) ** 2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluierung/Test\n",
    "\n",
    "<img src=\"img/ag/Figure-01-009.png\" style=\"width: 70%; margin-left: auto; margin-right: auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Evaluieren des Modells:\n",
    "(Hinweis: Broadcasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(1.0)\n",
    "b = torch.tensor(0.0)\n",
    "w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model(x, w, b)\n",
    "y_true = y\n",
    "y_pred[:5], y_true[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(y_pred, y_true)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training\n",
    "\n",
    "<br/>\n",
    "<img src=\"img/ag/Figure-01-008.png\" style=\"width: 100%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wie updaten wir die Parameter?\n",
    "\n",
    "<img src=\"img/ag/Figure-05-006.png\" style=\"width: 50%; margin-left: auto; margin-right: auto; 0\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wie updaten wir die Parameter?\n",
    "\n",
    "<img src=\"img/ag/Figure-05-007.png\" style=\"width: 50%; margin-left: auto; margin-right: auto; 0\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameter(p, rate_of_change, learning_rate = 1e-2):\n",
    "    p -= learning_rate * rate_of_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mathematisch\n",
    "$$\\nabla_{w, b} L = \\Bigl(\\frac{\\partial L}{\\partial w}, \\frac{\\partial L}{\\partial b} \\Bigr)\n",
    "= \\Bigl(\\frac{\\partial L}{\\partial m}\\cdot\\frac{\\partial m}{\\partial w},\n",
    "\\frac{\\partial L}{\\partial m} \\cdot \\frac{\\partial m}{\\partial b} \\Bigr)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, w, b):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmodel_dw(x, w, b):\n",
    "    return x\n",
    "def dmodel_db(x, w, b):\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\\nabla_{w, b} L \n",
    "= \\Bigl(\\frac{\\partial L}{\\partial m}\\cdot\\frac{\\partial m}{\\partial w},\n",
    "\\frac{\\partial L}{\\partial m} \\cdot \\frac{\\partial m}{\\partial b} \\Bigr)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_fn(x, y_pred, y_true, w, b):\n",
    "    dloss_dm = 2 * (y_pred - y_true) / y_pred.size(0)\n",
    "    dm_dw = dloss_dm * dmodel_dw(x, w, b)\n",
    "    dm_db = dloss_dm * dmodel_db(x, w, b)\n",
    "    return torch.stack([dm_dw.sum(), dm_db.sum()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training\n",
    "\n",
    "<br/>\n",
    "<img src=\"img/ag/Figure-01-008.png\" style=\"width: 100%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Training-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, x, y_true):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w, b = params\n",
    "        # _.forward()\n",
    "        y_pred = model(x, w, b)\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "        gradient = gradient_fn(x, y_pred, y_true, w, b)\n",
    "        # _.backward()\n",
    "        params = params - learning_rate * gradient\n",
    "        if epoch < 5 or epoch % (n_epochs // 10) == 0:\n",
    "            print(f\"Epoch {epoch:4}: loss = {loss.item():8.3f} \"\n",
    "                  f\"(w = {w.item():6.3f}, b = {b.item():6.3f}, \"\n",
    "                  f\"gradient = ({gradient[0]:.3f}, {gradient[1]:.3f})\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(\n",
    "    n_epochs=100,\n",
    "    learning_rate=0.1,\n",
    "    params=torch.tensor([1.0, 0.0]),\n",
    "    x=x,\n",
    "    y_true=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wie viel updaten wir die Parameter?\n",
    "\n",
    "<img src=\"img/ag/Figure-19-013.png\" style=\"width: 80%; margin-left: auto; margin-right: auto; 0\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wie viel updaten wir die Parameter?\n",
    "\n",
    "<img src=\"img/ag/Figure-19-014.png\" style=\"width: 80%; margin-left: auto; margin-right: auto; 0\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Wie viel updaten wir die Parameter?\n",
    "\n",
    "<img src=\"img/ag/Figure-19-015.png\" style=\"width: 80%; margin-left: auto; margin-right: auto; 0\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Wie viel updaten wir die Parameter?\n",
    "\n",
    "<img src=\"img/ag/Figure-19-016.png\" style=\"width: 80%; margin-left: auto; margin-right: auto; 0\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(\n",
    "    n_epochs=100,\n",
    "    learning_rate=0.01,\n",
    "    params=torch.tensor([1.0, 0.0]),\n",
    "    x=x,\n",
    "    y_true=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = training_loop(\n",
    "    n_epochs=1000,\n",
    "    learning_rate=1e-2,\n",
    "    params=torch.tensor([1.0, 0.0]),\n",
    "    x=x,\n",
    "    y_true=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x, *params)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x, y_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Workshop\n",
    "\n",
    "- Notebook 010x Workshop Einführung\n",
    "- Abschnitt \"Lineare Regression\"\n",
    "\n",
    "*Hinweis:* Bitte versuchen Sie die Lösung so weit wie möglich ohne Bezugnahme auf dieses Notebook zu lösen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Normalisieren der Inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x.mean()\n",
    "x_std = x.std()\n",
    "y_mean = y.mean()\n",
    "y_std = y.std()\n",
    "x_mean, x_std, y_mean, y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = (x - x_mean) / x_std\n",
    "y_norm = (y - y_mean) / y_std\n",
    "y_norm[:5], y_norm.mean(), y_norm.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = training_loop(\n",
    "    n_epochs=1000,\n",
    "    learning_rate=1e-2,\n",
    "    params=torch.tensor([1.0, 0.0]),\n",
    "    x=x_norm,\n",
    "    y_true=y_norm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_norm, *params) * y_std + y_mean\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x_norm * x_std + x_mean, y_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mini Workshop\n",
    "\n",
    "- Notebook 010x Workshop Einführung\n",
    "- Abschnitt \"Normierte Parameter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autograd\n",
    "\n",
    "Das Berechnen der Gradienten ist mühsam und fehleranfällig.\n",
    "\n",
    "PyTorch kann das für uns übernehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def model(x, w, b):\n",
    "    return w * x + b\n",
    "\n",
    "def loss_fn(y_pred, y_true):\n",
    "    squared_diffs = (y_pred - y_true) ** 2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(model(x, *params), y)\n",
    "loss.backward()\n",
    "\n",
    "params.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Was passiert, wenn wir die Loss-Funktion mehrmals auswerten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(model(x, *params), y)\n",
    "loss.backward()\n",
    "\n",
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "if params.grad is not None:\n",
    "    params.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, x, y_true):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "            \n",
    "        # model.forward()\n",
    "        y_pred = model(x, *params)\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            params -= learning_rate * params.grad\n",
    "            if epoch < 5 or epoch % (n_epochs // 10) == 0:\n",
    "                print(f\"Epoch {epoch:4}: loss = {loss.item():8.3f} \"\n",
    "                      f\"(w = {params[0].item():6.3f}, b = {params[1].item():6.3f}, \"\n",
    "                      f\"gradient = ({params.grad[0]:.3f}, {params.grad[1]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "training_loop(\n",
    "    n_epochs=1000,\n",
    "    learning_rate=1e-2,\n",
    "    params=torch.tensor([1.0, 0.0], requires_grad=True),\n",
    "    x=x,\n",
    "    y_true=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mini Workshop\n",
    "\n",
    "- Notebook 010x Workshop Einführung\n",
    "- Abschnitt \"Autograd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimierer\n",
    "\n",
    "- Pytorch hat mehrere Optimierungsstrategien\n",
    "- Diese arbeiten auf Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "[name for name in dir(optim) if name[0] != '_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x, *params)\n",
    "loss = loss_fn(y_pred, y_true)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x, *params)\n",
    "loss = loss_fn(y_pred, y_true)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, x, y_true):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # model.forward()\n",
    "        y_pred = model(x, *params)\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch < 5 or epoch % (n_epochs // 10) == 0:\n",
    "            print(f\"Epoch {epoch:4}: loss = v{loss.item():8.3f} \"\n",
    "                  f\"(w = {params[0].item():6.3f}, b = {params[1].item():6.3f}, \"\n",
    "                  f\"gradient = ({params.grad[0]:.3f}, {params.grad[1]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "training_loop(\n",
    "    n_epochs=1000,\n",
    "    optimizer=optimizer,\n",
    "    params=params,\n",
    "    x=x,\n",
    "    y_true=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "training_loop(\n",
    "    n_epochs=1000,\n",
    "    optimizer=optimizer,\n",
    "    params=params,\n",
    "    x=x,\n",
    "    y_true=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Randomisierung, Test/Validation/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "n_samples = x.shape[0]\n",
    "n_validation = math.floor(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "shuffled_indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = shuffled_indices[:-n_validation]\n",
    "validation_indices = shuffled_indices[-n_validation:]\n",
    "train_indices[:5], validation_indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_x = x[train_indices]\n",
    "train_y = y[train_indices]\n",
    "validation_x = x[validation_indices]\n",
    "validation_y = y[validation_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, x_train, y_train, x_val, y_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        y_train_pred = model(x_train, *params)\n",
    "        loss_train = loss_fn(y_train_pred, y_train)\n",
    "\n",
    "        y_val_pred = model(x_val, *params)\n",
    "        loss_val = loss_fn(y_val_pred, y_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch < 5 or epoch % (n_epochs // 10) == 0:\n",
    "            print(f\"Epoch {epoch:4}: training loss = {loss_train.item():8.3f}, \"\n",
    "                  f\"validation loss = {loss_val.item():8.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "training_loop(\n",
    "    n_epochs=1000,\n",
    "    optimizer=optimizer,\n",
    "    params=params,\n",
    "    x_train=train_x,\n",
    "    y_train=train_y,\n",
    "    x_val=validation_x,\n",
    "    y_val=validation_y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mini Workshop\n",
    "\n",
    "- Notebook 010x Workshop Einführung\n",
    "- Abschnitt \"Optimierer, Randomisierung\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pytorch Module und Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "linear_model = nn.Linear(1, 1, bias=True)\n",
    "linear_model(torch.tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Fehler\n",
    "# linear_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, x.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model(x.unsqueeze(-1))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Hinweis:* Bei Modulen definiert man `forward()`, ruft sie aber als Funktion auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "linear_model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(1, 1)\n",
    "optimizer = optim.SGD(\n",
    "    linear_model.parameters(),\n",
    "    lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(linear_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, x_train, y_train, x_val, y_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        y_train_pred = model(x_train)\n",
    "        loss_train = loss_fn(y_train_pred, y_train)\n",
    "\n",
    "        y_val_pred = model(x_val)\n",
    "        loss_val = loss_fn(y_val_pred, y_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch < 5 or epoch % (n_epochs // 10) == 0:\n",
    "            print(f\"Epoch {epoch:4}: training loss = {loss_train.item():8.3f}, \"\n",
    "                  f\"validation loss = {loss_val.item():8.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(1, 1)\n",
    "optimizer = optim.SGD(\n",
    "    linear_model.parameters(),\n",
    "    lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "training_loop(\n",
    "    n_epochs=1000,\n",
    "    optimizer=optimizer,\n",
    "    model=linear_model,\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    x_train=train_x.unsqueeze(-1),\n",
    "    y_train=train_y.unsqueeze(-1),\n",
    "    x_val=validation_x.unsqueeze(-1),\n",
    "    y_val=validation_y.unsqueeze(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mini Workshop\n",
    "\n",
    "- Notebook 010x Workshop Einführung\n",
    "- Abschnitt \"Module, Batching\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:ml-training] *",
   "language": "python",
   "name": "conda-env-ml-training-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
